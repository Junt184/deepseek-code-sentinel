【阶段三：前端交互与流式反馈（Frontend & Visualization）论文素材】

1. 学术背景/动机
在交互式安全分析场景中，端到端延迟与“等待体验”是影响系统可用性的重要因素。大语言模型推理具有显著的不确定性与长尾延迟，若前端只能在请求结束后一次性展示结果，用户易产生“系统卡死”的主观感受。本阶段以流式输出与可视化定位为核心，旨在将不可预测的模型推理过程转化为可感知、可解释的进度反馈，从而提升用户对系统稳定性的信任。

2. 核心方案说明
阶段三实现了“流式输出链路 + 代码定位可视化”的组合方案：
（1）后端流式输出：在 LLM 调用侧启用 `stream=True`，将模型增量 token（或增量文本片段）作为异步生成器逐段产出，并以 `StreamingResponse` 返回给前端；
（2）前端流式消费：前端基于 Fetch 的 `ReadableStream` 读取响应体，使用 `TextDecoder` 将字节流解码为文本，形成“逐段追加”的展示效果；
（3）结果呈现：前端在流式阶段展示 raw 文本，流结束后尝试对累积文本进行 JSON 解析，解析成功则渲染结构化漏洞卡片与摘要；解析失败则保留 raw 文本作为可见的降级路径；
（4）代码定位：基于 Monaco Editor 的装饰器机制（decorations），对漏洞 `line` 所指向的行进行高亮标记，并通过 hover 提示显示风险摘要，形成“报告-代码”的可追溯映射。

3. 论文加分项（Academic Highlights）
（1）将推理过程可视化：把 LLM 的生成过程转化为可感知的交互反馈，可作为“可解释性/可用性”贡献论述。
（2）流式传输的容错：流结束后再解析 JSON，并提供解析失败的降级展示，可在论文中作为鲁棒交互设计案例。
（3）风险定位映射：利用编辑器装饰器将结构化漏洞与源码行号绑定，体现“可操作性（actionability）”设计理念。

4. 实验/验证数据
（1）可达性验证：前端开发服务器运行于 `http://localhost:5173`，可发起对后端 `http://localhost:8000` 的分析请求。
（2）交互验证：在浏览器中点击“开始审计”后，右侧面板出现持续追加的流式文本；流结束后可渲染审计摘要与漏洞列表。
（3）注意事项（可写入论文“限制”）：当前后端以 `text/event-stream` 作为 media_type，但未采用标准 SSE 的事件帧格式（`data:`/`event:`）。前端使用 Fetch 流读取可正常工作，但若采用 `EventSource` 则需要补齐 SSE 帧协议。

