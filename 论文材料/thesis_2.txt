【阶段二：核心分析引擎构建（Core Analysis Engine）论文素材】

1. 学术背景/动机
阶段二的核心目标是将“代码安全分析任务”交由大语言模型执行，并获得可用于自动化处理的结构化输出。学术上，这对应两个关键问题：（1）如何通过提示词工程与输出约束，将概率生成模型的自由文本输出映射为可解析的结构化 JSON；（2）如何以异步方式集成外部模型服务，保证系统在 IO 主导场景下的吞吐稳定性。

2. 核心方案说明
本阶段引入独立的 LLM 客户端服务层，实现“业务接口”与“模型调用”解耦：
（1）调用层：使用异步客户端封装对 DeepSeek 的 Chat Completion 调用，并通过 `base_url` 与 `api_key` 注入配置，实现供应商可替换性；
（2）提示词工程：采用 System Prompt + User Prompt 的分层结构。在 User Prompt 中显式给出 JSON Schema（字段 `severity/line/description/suggestion/summary`），并要求“仅输出 JSON 对象”；在 System Prompt 中强化约束条件（中文输出、必须为 JSON）；
（3）结构化解析：将模型返回的 `message.content` 作为 JSON 字符串解析。为避免格式漂移，调用侧启用 `response_format={"type":"json_object"}`（依赖模型能力），以降低非 JSON 输出概率；
（4）错误兜底：当调用或解析失败时，返回带 `status=error` 的降级结构，避免后端崩溃并保留可观测错误信息。

3. 论文加分项（Academic Highlights）
（1）“结构化输出约束”可作为方法论章节的重点：讨论 LLM 输出空间约束（JSON 模式、低温度、显式 schema）的组合策略，以及它对鲁棒性的影响。
（2）服务层解耦：LLMService 抽象为独立组件，体现软件架构中“边界清晰”的工程哲学，可在论文中对比“直接在路由中调用模型”的反例。
（3）中文结果生成：针对中文受众的安全报告生成，体现人机交互与可理解性维度的优化目标。

4. 实验/验证数据
（1）功能验证：`POST /api/v1/analyze` 在配置有效 API Key 时可返回中文 `summary`（示例输出包含“命令注入漏洞”描述），证明提示词约束对输出语言有效。
（2）单元测试：`pytest -q` 运行通过（3/3）。测试覆盖健康检查与接口契约（通过 monkeypatch 替换 LLM 调用实现）与空输入拒绝。
（3）错误路径验证：当 API Key 无效或未配置时，服务返回可解释的失败信息（未配置时 HTTP 503；鉴权失败时返回 `status=failed` 且 summary 包含鉴权错误描述）。

